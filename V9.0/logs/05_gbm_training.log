Loading feature data from 'training_dataset.csv'...
Loaded 35219 matches for GBM re-training.
Training with 12 features: ['Time_Since_Last_Advantage', 'Matches_Last_24H_Advantage', 'Is_First_Match_Advantage', 'PDR_Slope_Advantage', 'H2H_P1_Win_Rate', 'H2H_Dominance_Score', 'Daily_Fatigue_Advantage', 'PDR_Advantage', 'Win_Rate_Advantage', 'Win_Rate_L5_Advantage', 'Close_Set_Win_Rate_Advantage', 'Set_Comebacks_Advantage']
Preprocessing data with symmetrical features...

Starting GridSearchCV to find the best model parameters...
Fitting 3 folds for each of 8 candidates, totalling 24 fits
Best parameters found: {'learning_rate': 0.05, 'max_depth': 2, 'min_samples_leaf': 50, 'n_estimators': 100, 'subsample': 0.7}

[OK] Successfully re-trained and saved the GBM model to 'cpr_v7.4_gbm_specialist.joblib'
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.7; total time=   5.0s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.7; total time=   5.1s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.7; total time=   5.1s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.7; total time=   5.2s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.8; total time=   5.3s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.8; total time=   5.4s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.8; total time=   5.6s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.8; total time=   5.7s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.7; total time=   4.4s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.7; total time=   3.6s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.7; total time=   4.4s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.7; total time=   3.7s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.7; total time=   4.2s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.8; total time=   3.9s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.7; total time=   4.3s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.8; total time=   3.9s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.8; total time=   5.0s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.7; total time=   3.4s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.8; total time=   5.0s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.8; total time=   3.6s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.8; total time=   4.9s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.8; total time=   3.6s
[CV] END learning_rate=0.01, max_depth=2, min_samples_leaf=40, n_estimators=100, subsample=0.7; total time=   5.0s
[CV] END learning_rate=0.05, max_depth=2, min_samples_leaf=50, n_estimators=100, subsample=0.8; total time=   3.8s
